{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFJvwae9M8Qc"
      },
      "source": [
        "# Experiment Design - Analyzing and Predicting News Popularity in an Instant Messaging Service\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Within this notebook the single task learning model, **STL-All** (SVM classifier trained on all the data from all channels) is implemented based on the Paper Analyzing and Predicting News Popularity in an Instant Messaging Service. It is checked whether or not the implementation and the results reported in the paper are reproducible and what information might be missing or wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izdLDoFfPKU2"
      },
      "source": [
        "## Get Data & Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puWsajoBPIDR",
        "outputId": "39c47b5d-8b42-4a88-95b6-115252590c10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'TelegramNews'...\n",
            "Updating files:  36% (7/19)\n",
            "Updating files:  42% (8/19)\n",
            "Updating files:  47% (9/19)\n",
            "Updating files:  52% (10/19)\n",
            "Updating files:  57% (11/19)\n",
            "Updating files:  63% (12/19)\n",
            "Updating files:  68% (13/19)\n",
            "Updating files:  73% (14/19)\n",
            "Updating files:  78% (15/19)\n",
            "Updating files:  84% (16/19)\n",
            "Updating files:  89% (17/19)\n",
            "Updating files:  94% (18/19)\n",
            "Updating files: 100% (19/19)\n",
            "Updating files: 100% (19/19), done.\n"
          ]
        }
      ],
      "source": [
        "# Run only if needed, e.g. when the Telegram News Folder is not yet downloaded!\n",
        "! git clone https://github.com/IceCream71/TelegramNews.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPSSoODVXoqR"
      },
      "outputs": [],
      "source": [
        "#with open ('/content/TelegramNews/mongo/telegram/cnnbrk.json', 'rb') as f:\n",
        "#  data = pd.read_json(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQbY8mymYCYM"
      },
      "outputs": [],
      "source": [
        "#df = pd.DataFrame(data)\n",
        "#print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nopdga5Y69p"
      },
      "source": [
        "missing features (which can't be calculated due to missing information): \n",
        "\n",
        "\n",
        "* subscribers (shows the popularity of channel)\n",
        "* channel age (date of first post? in days)\n",
        "* frequent n-grams (frequent n-grams that news item contains)\n",
        "* frequent hashtags (frequent hashtags that news item contains)\n",
        "* frequent mentions (frequent mentions that news item contains)\n",
        "\n",
        "what does frequent mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nMQsLJJvMv2F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import bson\n",
        "import seaborn as sns\n",
        "\n",
        "def create_df_for_bson(path, channel): \n",
        "  with open (path, 'rb') as f:\n",
        "    data = bson.decode_all(f.read())\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  df = handle_NAS(df)\n",
        "  df = extract_features(df)\n",
        "  df = cut_date_range(df)\n",
        "  df = drop_unused_features(df)\n",
        "  df = add_channel(df, channel)\n",
        "  return df\n",
        "\n",
        "def handle_NAS(df):\n",
        "  df = df.dropna(subset=['views'],axis=0)\n",
        "  return df\n",
        "\n",
        "def extract_features(df):\n",
        "  df = create_datetime_features(df)\n",
        "  df = add_channel_features(df)\n",
        "  df = create_entity_features(df)\n",
        "  return df\n",
        "\n",
        "def create_datetime_features(df):\n",
        "  df['age'] =  df.date\n",
        "  df['date'] = pd.to_datetime(df.date, unit='s')\n",
        "  df['year'] = df.date.dt.year\n",
        "  df['month'] = df.date.dt.month\n",
        "  df['day'] = df.date.dt.day\n",
        "  df['weekday'] = df.date.dt.dayofweek\n",
        "  df['hour'] = df.date.dt.hour\n",
        "  return df\n",
        "\n",
        "def cut_date_range(df):\n",
        "  # March 8, 2017 to October 8, 2017.\n",
        "  start_date = \"2017-03-08\"\n",
        "  end_date  = \"2017-10-08\"\n",
        "  mask = (df.date > start_date) & (df.date <= end_date)\n",
        "  return df.loc[mask]\n",
        "\n",
        "def add_channel_features(df):\n",
        "  df['minViews'] = df.views.min()\n",
        "  df['maxViews'] = df.views.max()\n",
        "  df['meanViews'] = df.views.mean()\n",
        "  df['stdViews'] = df.views.std()\n",
        "  df['avgPostsHour'] = df.groupby('hour').size().mean()\n",
        "  df['avgPostsDay'] = df.groupby(['year', 'month', 'day']).size().mean()\n",
        "  return df\n",
        "\n",
        "def create_entity_features(df):\n",
        "  # Convert the entity field from bson into the actual features.\n",
        "  # For each row, check if media exists, if yes set media type.\n",
        "  df['hasMedia'] = df.media.notnull()\n",
        "  df['mediaType'] = df.apply(lambda x: x.media['_'] if x.hasMedia else '', axis=1)\n",
        "  # Check if URL exists in entities, if exists, is a link\n",
        "  df['hasLink'] = df.apply(lambda x: True if type(x.entities) != float and [d for d in x.entities if d['_'] ==  'messageEntityTextUrl'] else False, axis=1)\n",
        "  # Collect the mentions from the entities feature\n",
        "  df['mentions'] = df.apply(lambda x: len([d for d in x.entities if d['_'] == 'messageEntityMention']) if type(x.entities) != float else 0, axis=1)\n",
        "  # Same as before for the hashtags\n",
        "  df['hashtags'] = df.apply(lambda x: len([d for d in x.entities if d['_'] == 'messageEntityHashtag']) if type(x.entities) != float else 0, axis=1)\n",
        "  return df\n",
        "\n",
        "# keep needed features, more flexible as different datasets contain different features\n",
        "def drop_unused_features(df):\n",
        "  return df.drop(df.columns.difference(['age', 'date', 'year', 'month', 'day', 'weekday', \n",
        "                          'hour', 'minViews', 'maxViews', 'meanViews', 'stdViews',\n",
        "                          'hasMedia', 'mediaType', 'hasLink', 'mentions', 'hashtags', 'views']),axis=1)\n",
        "\n",
        "def add_channel(df, channel):\n",
        "    df['channel']=channel\n",
        "    return df\n",
        "\n",
        "\n",
        " \n",
        "reutersWorld = create_df_for_bson('TelegramNews/mongo/telegram/ReutersWorld.bson', 'reutersWorld')\n",
        "cnnBrk = create_df_for_bson('TelegramNews/mongo/telegram/CNNBrk.bson', 'cnnBrk')\n",
        "#theGuardian = create_df_for_bson('/content/TelegramNews/mongo/telegram/TheGuardian.bson', 'theGuardian')\n",
        "bbcBreaking = create_df_for_bson('TelegramNews/mongo/telegram/bbcbreaking.bson', 'bbc')\n",
        "bbcPersian = create_df_for_bson('TelegramNews/mongo/telegram/bbcpersian.bson', 'bbc')\n",
        "pressTV = create_df_for_bson('TelegramNews/mongo/telegram/presstv.bson', 'pressTV')\n",
        "washingtonPost = create_df_for_bson('TelegramNews/mongo/telegram/washingtonpost.bson', 'washingtonPost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzH389i6j8e5"
      },
      "source": [
        "In the paper it is not clearly stated which datasets are included in training SVM all. In the repository we found more datasets than the ones listed in the table comparing the different models. Hence we simply assumed that for training SVM all, all available datasets (except the Guardian as it doesn't contain data) are used and only the ones listed in the mentioned table are used for prediction.\n",
        "\n",
        "Also they predicted BBC, however two datasets called bbcBreaking and bbcPersian do exist. It is not clear if BBC simply combines these two, or if only one of them is chosen as BBC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nIEwfqPHfEDR"
      },
      "outputs": [],
      "source": [
        "dfs = [reutersWorld, cnnBrk, bbcBreaking, bbcPersian, pressTV, washingtonPost]\n",
        "all = pd.concat(dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq7F0HsREIp6"
      },
      "source": [
        "We assumed that the train and test split is done first according to *Therefore, we first found the thresholds that satisfy these percentages for training and test sets and assigned a binary label to each post*. Also, if the split is done after assigning the popularity, in e.g. the cnn test set no popular posts can be found and the prediction would have an accuracy of 1.0, which is not the case in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4jaMnjBW5md",
        "outputId": "4f545307-6399-4984-fbdc-9531913996a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of Training set: 64916\n",
            "Size of Test set: 11056\n",
            "Percentage of train split: 85.45%\n"
          ]
        }
      ],
      "source": [
        "def create_train_test_split(df):\n",
        "  # the first six months (March - September) of the data is selected for training and the last month (October)\n",
        "  # is selected for testing.\n",
        "   # March 8, 2017 to September 7, 2017.\n",
        "  train_start = \"2017-03-08\"\n",
        "  train_end = \"2017-09-07\"\n",
        "  mask = (df.date > train_start) & (df.date <= train_end)\n",
        "\n",
        "  df = df.drop(labels=['date'],axis=1)\n",
        "  df.mediaType = df.mediaType.astype('category').cat.codes\n",
        "\n",
        "  training = df.loc[mask]\n",
        "  test = df.loc[-mask]\n",
        "\n",
        "  return training, test\n",
        "\n",
        "allTrain, allTest = create_train_test_split(all)\n",
        "\n",
        "print(f\"Size of Training set: {len(allTrain.index)}\")\n",
        "print(f\"Size of Test set: {len(allTest.index)}\")\n",
        "print(f\"Percentage of train split: {round(100 * len(allTrain.index) / len(all.index),2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpXMsY1iDyKe"
      },
      "source": [
        "It is not clearly stated in the paper how the threshold which is used to state whether a post is popular or not is defined. In this case it is assumed, that the more views a post has, the more popular it is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ov8CprrDDKFk"
      },
      "outputs": [],
      "source": [
        "# popular = 1\n",
        "# not popular = 0\n",
        "\n",
        "def assign_popularity (df, percent):\n",
        "  df.sort_values(by=['views'], inplace=True, ascending=False)\n",
        "  \n",
        "  quantile = (100-percent)/100\n",
        "  threshold = df.loc[:,'views'].quantile(quantile)\n",
        "  is_popular = df.loc[:,'views'] > threshold\n",
        "\n",
        "  df.loc[is_popular,'Popular']=1\n",
        "  df.loc[~is_popular, 'Popular']=0\n",
        "\n",
        "  return df\n",
        "\n",
        "allTrain_5 = assign_popularity(allTrain, 5)\n",
        "allTest_5 = assign_popularity(allTest, 5)\n",
        "\n",
        "allTrain_25 = assign_popularity(allTrain, 25)\n",
        "allTest_25 = assign_popularity(allTest, 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           views         age  year  month  day  weekday  hour  minViews  \\\n",
            "2716   1908500.0  1501109574  2017      7   26        2    22   78130.0   \n",
            "4817   1482198.0  1495247786  2017      5   20        5     2   78130.0   \n",
            "5007   1475636.0  1494845222  2017      5   15        0    10   78130.0   \n",
            "4550   1364851.0  1495645444  2017      5   24        2    17   78130.0   \n",
            "5729   1233545.0  1492715698  2017      4   20        3    19   78130.0   \n",
            "...          ...         ...   ...    ...  ...      ...   ...       ...   \n",
            "52145        6.0  1489419870  2017      3   13        0    15       5.0   \n",
            "52167        6.0  1489418859  2017      3   13        0    15       5.0   \n",
            "52168        5.0  1489418858  2017      3   13        0    15       5.0   \n",
            "52169        5.0  1489418856  2017      3   13        0    15       5.0   \n",
            "52170        5.0  1489418855  2017      3   13        0    15       5.0   \n",
            "\n",
            "        maxViews      meanViews       stdViews  hasMedia  mediaType  hasLink  \\\n",
            "2716   2904081.0  415212.015241  122121.066533      True          1    False   \n",
            "4817   2904081.0  415212.015241  122121.066533     False          0    False   \n",
            "5007   2904081.0  415212.015241  122121.066533      True          2    False   \n",
            "4550   2904081.0  415212.015241  122121.066533     False          0    False   \n",
            "5729   2904081.0  415212.015241  122121.066533     False          0    False   \n",
            "...          ...            ...            ...       ...        ...      ...   \n",
            "52145    15277.0      89.836100      97.311753      True          3     True   \n",
            "52167    15277.0      89.836100      97.311753      True          3     True   \n",
            "52168    15277.0      89.836100      97.311753      True          3     True   \n",
            "52169    15277.0      89.836100      97.311753      True          3     True   \n",
            "52170    15277.0      89.836100      97.311753      True          3     True   \n",
            "\n",
            "       mentions  hashtags channel  Popular  \n",
            "2716          0         0     bbc      1.0  \n",
            "4817          1         0     bbc      1.0  \n",
            "5007          0         0     bbc      1.0  \n",
            "4550          1         0     bbc      1.0  \n",
            "5729          1         0     bbc      1.0  \n",
            "...         ...       ...     ...      ...  \n",
            "52145         0         0  cnnBrk      0.0  \n",
            "52167         0         0  cnnBrk      0.0  \n",
            "52168         0         0  cnnBrk      0.0  \n",
            "52169         0         0  cnnBrk      0.0  \n",
            "52170         0         0  cnnBrk      0.0  \n",
            "\n",
            "[64916 rows x 18 columns]\n"
          ]
        }
      ],
      "source": [
        "print(allTrain_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDnLqRrBC9MC",
        "outputId": "c7c8a1c0-6fe3-4441-937c-fa41375f63d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              views       age  year     month       day   weekday      hour  \\\n",
            "0      1.000000e+00  0.770360   0.0  0.666667  0.833333  0.333333  0.956522   \n",
            "1      7.766292e-01  0.399538   0.0  0.333333  0.633333  0.833333  0.086957   \n",
            "2      7.731909e-01  0.374071   0.0  0.333333  0.466667  0.000000  0.434783   \n",
            "3      7.151426e-01  0.424694   0.0  0.333333  0.766667  0.333333  0.739130   \n",
            "4      6.463418e-01  0.239356   0.0  0.166667  0.633333  0.500000  0.826087   \n",
            "...             ...       ...   ...       ...       ...       ...       ...   \n",
            "64911  5.239731e-07  0.030859   0.0  0.000000  0.400000  0.000000  0.652174   \n",
            "64912  5.239731e-07  0.030795   0.0  0.000000  0.400000  0.000000  0.652174   \n",
            "64913  0.000000e+00  0.030795   0.0  0.000000  0.400000  0.000000  0.652174   \n",
            "64914  0.000000e+00  0.030795   0.0  0.000000  0.400000  0.000000  0.652174   \n",
            "64915  0.000000e+00  0.030794   0.0  0.000000  0.400000  0.000000  0.652174   \n",
            "\n",
            "       minViews  maxViews  meanViews  stdViews  hasMedia  mediaType  hasLink  \\\n",
            "0           1.0  1.000000        1.0       1.0       1.0   0.333333      0.0   \n",
            "1           1.0  1.000000        1.0       1.0       0.0   0.000000      0.0   \n",
            "2           1.0  1.000000        1.0       1.0       1.0   0.666667      0.0   \n",
            "3           1.0  1.000000        1.0       1.0       0.0   0.000000      0.0   \n",
            "4           1.0  1.000000        1.0       1.0       0.0   0.000000      0.0   \n",
            "...         ...       ...        ...       ...       ...        ...      ...   \n",
            "64911       0.0  0.004511        0.0       0.0       1.0   1.000000      1.0   \n",
            "64912       0.0  0.004511        0.0       0.0       1.0   1.000000      1.0   \n",
            "64913       0.0  0.004511        0.0       0.0       1.0   1.000000      1.0   \n",
            "64914       0.0  0.004511        0.0       0.0       1.0   1.000000      1.0   \n",
            "64915       0.0  0.004511        0.0       0.0       1.0   1.000000      1.0   \n",
            "\n",
            "       mentions  hashtags  Popular  \n",
            "0      0.000000       0.0      1.0  \n",
            "1      0.020408       0.0      1.0  \n",
            "2      0.000000       0.0      1.0  \n",
            "3      0.020408       0.0      1.0  \n",
            "4      0.020408       0.0      1.0  \n",
            "...         ...       ...      ...  \n",
            "64911  0.000000       0.0      0.0  \n",
            "64912  0.000000       0.0      0.0  \n",
            "64913  0.000000       0.0      0.0  \n",
            "64914  0.000000       0.0      0.0  \n",
            "64915  0.000000       0.0      0.0  \n",
            "\n",
            "[64916 rows x 17 columns]\n"
          ]
        }
      ],
      "source": [
        "# Apply Min-Max scaling fitted on the training data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "#training\n",
        "scaled_training_5 = pd.DataFrame(scaler.fit_transform(allTrain_5.drop('channel', axis=1)), columns=allTrain_5.drop('channel', axis=1).columns)\n",
        "scaled_training_25 = pd.DataFrame(scaler.fit_transform(allTrain_25.drop('channel', axis=1)), columns=allTrain_25.drop('channel', axis=1).columns)\n",
        "#test\n",
        "scaled_test_5 = pd.DataFrame(scaler.transform(allTest_5.drop('channel', axis=1)), columns=allTest_5.drop('channel', axis=1).columns)\n",
        "scaled_test_25 = pd.DataFrame(scaler.transform(allTest_25.drop('channel', axis=1)), columns=allTest_25.drop('channel', axis=1).columns)\n",
        "\n",
        "\n",
        "def scale_partial(df, channel):\n",
        "  is_channel = df.loc[:, 'channel']==channel\n",
        "  channel_df = df.loc[is_channel]\n",
        "  return pd.DataFrame(scaler.transform(channel_df.drop('channel', axis=1)), \n",
        "                      columns=channel_df.drop('channel', axis=1).columns)\n",
        "\n",
        "cnn_scaled_test_5 = scale_partial(allTest_5, 'cnnBrk')\n",
        "reuters_scaled_test_5 = scale_partial(allTest_5, 'reutersWorld')\n",
        "press_scaled_test_5 = scale_partial(allTest_5, 'pressTV')\n",
        "bbc_scaled_test_5 = scale_partial(allTest_5, 'bbc')\n",
        "\n",
        "cnn_scaled_test_25 = scale_partial(allTest_25, 'cnnBrk')\n",
        "reuters_scaled_test_25 = scale_partial(allTest_25, 'reutersWorld')\n",
        "press_scaled_test_25 = scale_partial(allTest_25, 'pressTV')\n",
        "bbc_scaled_test_25 = scale_partial(allTest_25, 'bbc')\n",
        "\n",
        "print(scaled_training_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd5MOr3PkAFn"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Aim is to predict top 5% and top 25% popular news for each agency. Therefore train svm classifier on all channels and predict popular news for only one **channel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0DaQ2NEQrkBv"
      },
      "outputs": [],
      "source": [
        "def calculate_weights(train_df):\n",
        "  n = len(train_df.index)\n",
        "  labels = train_df.Popular\n",
        "  popular = len(labels[labels == 1])\n",
        "  not_popular = n - popular\n",
        "\n",
        "  denominator = sum((1 / (popular if labels[k] == 1 else not_popular)) for k in range(1,n))\n",
        "  bigLambda = map(lambda i: (1 / (popular if labels[i] == 1 else not_popular)) * denominator, range(0, n))\n",
        "  return pd.Series(bigLambda)\n",
        "\n",
        "weights_5 = calculate_weights(scaled_training_5)\n",
        "weights_25 = calculate_weights(scaled_training_25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSkQxVHUjnvh"
      },
      "source": [
        "### Top 5%\n",
        "Interestingly using GridSearch including the weights as stated in the paper, the results are way more different than simply applying svc (using default settings). If adding the weights to the simple svc implementation, the results turn out to be exactly the same as when using the gridSearch implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y5 = scaled_training_5['Popular']\n",
        "x5 = scaled_training_5.drop('Popular', axis=1)\n",
        "\n",
        "param_grid = {'C' : np.logspace(-3, 2, 6)}\n",
        "weight_array = weights_5.unique()\n",
        "weight_dict = {0 : weight_array[0], 1 : weight_array[1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = svm.SVC()\n",
        "clf.fit(x5, y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LHwtOJxj2frr"
      },
      "outputs": [],
      "source": [
        "svc_classifier_grid = GridSearchCV(svm.SVC(), param_grid=param_grid)\n",
        "clf_grid = svc_classifier_grid.fit(x5,y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc_classifier_grid = GridSearchCV(svm.SVC(class_weight=weight_dict), param_grid=param_grid, n_jobs=8)\n",
        "clf_grid_weighted = svc_classifier_grid.fit(x5,y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dLxfKzwJmXMh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ]
        }
      ],
      "source": [
        "svc_classifier_grid = GridSearchCV(svm.LinearSVC(), cv=5, param_grid=param_grid, n_jobs=8)\n",
        "clf_grid_linear = svc_classifier_grid.fit(x5,y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc_classifier_grid = GridSearchCV(svm.LinearSVC(class_weight=weight_dict), param_grid=param_grid, cv=5, n_jobs=8)\n",
        "clf_grid_weighted_linear = svc_classifier_grid.fit(x5,y5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prediction + Evaluation of Top5% models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3vSyYjt_4SyV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "def model_metrics(true, predicted):\n",
        "  acc = accuracy_score(true, predicted)\n",
        "  ba = balanced_accuracy_score(true, predicted)\n",
        "  prec = precision_score(true, predicted)\n",
        "  recall = recall_score(true, predicted)\n",
        "  f1 = f1_score(true, predicted)\n",
        "\n",
        "  print('Accuracy: ', acc)\n",
        "  print('Balanced Accuracy: ', ba)\n",
        "  print('Precision: ', prec)\n",
        "  print('Recall: ', recall)\n",
        "  print('F1: ', f1)\n",
        "\n",
        "  return confusion_matrix(true, predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtanoHpe9N5P"
      },
      "source": [
        "Prediction for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hbps_0U9QOX",
        "outputId": "606f571c-03c1-4df8-b25f-8e59842f9462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  0.9384684147794994\n",
            "Balanced Accuracy:  0.5492895169344248\n",
            "Precision:  0.0075\n",
            "Recall:  0.15789473684210525\n",
            "F1:  0.01431980906921241\n",
            "[[6296  397]\n",
            " [  16    3]]\n"
          ]
        }
      ],
      "source": [
        "y5_cnn_test = cnn_scaled_test_5['Popular']\n",
        "x5_cnn_test = cnn_scaled_test_5.drop('Popular', axis=1)\n",
        "\n",
        "cnn_default = clf.predict(x5_cnn_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y5_cnn_test, cnn_default))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  0.9408522050059595\n",
            "Balanced Accuracy:  0.55048479558376\n",
            "Precision:  0.0078125\n",
            "Recall:  0.15789473684210525\n",
            "F1:  0.01488833746898263\n",
            "[[6312  381]\n",
            " [  16    3]]\n"
          ]
        }
      ],
      "source": [
        "cnn_grid = clf_grid.predict(x5_cnn_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y5_cnn_test, cnn_grid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.9971692491060786\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[6693    0]\n",
            " [  19    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_weighted = clf_grid_weighted.predict(x5_cnn_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y5_cnn_test, cnn_grid_weighted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear\n",
            "Accuracy:  0.9971692491060786\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[6693    0]\n",
            " [  19    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_linear = clf_grid_linear.predict(x5_cnn_test)\n",
        "print('grid - linear')\n",
        "print(model_metrics(y5_cnn_test, cnn_grid_linear))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.9971692491060786\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[6693    0]\n",
            " [  19    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_linear_weighted = clf_grid_weighted_linear.predict(x5_cnn_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y5_cnn_test, cnn_grid_linear_weighted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for BBC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToPEXAIxGYrp",
        "outputId": "4dfdfeb1-0c87-4291-b4b9-9237822e45e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  1.0\n",
            "Balanced Accuracy:  1.0\n",
            "Precision:  1.0\n",
            "Recall:  1.0\n",
            "F1:  1.0\n",
            "[[1148]]\n"
          ]
        }
      ],
      "source": [
        "y5_bbc_test = bbc_scaled_test_5['Popular']\n",
        "x5_bbc_test = bbc_scaled_test_5.drop('Popular', axis=1)\n",
        "\n",
        "bbc_default = clf.predict(x5_bbc_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y5_bbc_test, bbc_default))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  1.0\n",
            "Balanced Accuracy:  1.0\n",
            "Precision:  1.0\n",
            "Recall:  1.0\n",
            "F1:  1.0\n",
            "[[1148]]\n"
          ]
        }
      ],
      "source": [
        "bbc_grid = clf_grid.predict(x5_bbc_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y5_bbc_test, bbc_grid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.7970383275261324\n",
            "Balanced Accuracy:  0.7970383275261324\n",
            "Precision:  1.0\n",
            "Recall:  0.7970383275261324\n",
            "F1:  0.8870576829859428\n",
            "[[  0   0]\n",
            " [233 915]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ]
        }
      ],
      "source": [
        "bbc_grid_weighted = clf_grid_weighted.predict(x5_bbc_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y5_bbc_test, bbc_grid_weighted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.7970383275261324\n",
            "Balanced Accuracy:  0.7970383275261324\n",
            "Precision:  1.0\n",
            "Recall:  0.7970383275261324\n",
            "F1:  0.8870576829859428\n",
            "[[  0   0]\n",
            " [233 915]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ]
        }
      ],
      "source": [
        "bbc_grid_linear_weighted = clf_grid_weighted_linear.predict(x5_bbc_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y5_bbc_test, bbc_grid_linear_weighted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for Reuters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKvR5iOfHK2k",
        "outputId": "86e76e7e-c0d1-41b2-8f0c-4a6bc71a5184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  0.14085267134376686\n",
            "Balanced Accuracy:  0.5021888680425266\n",
            "Precision:  0.13759479956663057\n",
            "Recall:  1.0\n",
            "F1:  0.2419047619047619\n",
            "[[   7 1592]\n",
            " [   0  254]]\n"
          ]
        }
      ],
      "source": [
        "y5_reuters_test = reuters_scaled_test_5['Popular']\n",
        "x5_reuters_test = reuters_scaled_test_5.drop('Popular', axis=1)\n",
        "\n",
        "reuters_default = clf.predict(x5_reuters_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y5_reuters_test, reuters_default))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  0.14085267134376686\n",
            "Balanced Accuracy:  0.5021888680425266\n",
            "Precision:  0.13759479956663057\n",
            "Recall:  1.0\n",
            "F1:  0.2419047619047619\n",
            "[[   7 1592]\n",
            " [   0  254]]\n"
          ]
        }
      ],
      "source": [
        "reuters_grid = clf_grid.predict(x5_reuters_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y5_reuters_test, reuters_grid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.8629249865083648\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[1599    0]\n",
            " [ 254    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "reuters_grid_weighted = clf_grid_weighted.predict(x5_reuters_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y5_reuters_test, reuters_grid_weighted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.8629249865083648\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[1599    0]\n",
            " [ 254    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "reuters_grid_linear_weighted = clf_grid_weighted_linear.predict(x5_reuters_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y5_reuters_test, reuters_grid_linear_weighted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for PressTV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  0.14098360655737704\n",
            "Balanced Accuracy:  0.14098360655737704\n",
            "Precision:  1.0\n",
            "Recall:  0.14098360655737704\n",
            "F1:  0.24712643678160917\n",
            "[[   0    0]\n",
            " [1048  172]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ]
        }
      ],
      "source": [
        "y5_press_test = press_scaled_test_5['Popular']\n",
        "x5_press_test = press_scaled_test_5.drop('Popular', axis=1)\n",
        "\n",
        "press_default = clf.predict(x5_press_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y5_press_test, press_default))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  1.0\n",
            "Balanced Accuracy:  1.0\n",
            "Precision:  1.0\n",
            "Recall:  1.0\n",
            "F1:  1.0\n",
            "[[1220]]\n"
          ]
        }
      ],
      "source": [
        "press_grid = clf_grid.predict(x5_press_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y5_press_test, press_grid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.0\n",
            "Balanced Accuracy:  0.0\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[   0    0]\n",
            " [1220    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n",
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "press_grid_weighted = clf_grid_weighted.predict(x5_press_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y5_press_test, press_grid_weighted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.0\n",
            "Balanced Accuracy:  0.0\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[   0    0]\n",
            " [1220    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n",
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "press_grid_linear_weighted = clf_grid_weighted_linear.predict(x5_press_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y5_press_test, press_grid_linear_weighted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<hr>\n",
        "\n",
        "## Top 25%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "y25 = scaled_training_25['Popular']\n",
        "x25 = scaled_training_25.drop('Popular', axis=1)\n",
        "\n",
        "param_grid = {'C' : np.logspace(-3, 2, 6)}\n",
        "weight_array_25 = weights_25.unique()\n",
        "weight_dict_25 = {0 : weight_array_25[0], 1 : weight_array_25[1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# default SVM\n",
        "clf_25 = svm.SVC()\n",
        "clf_25.fit(x25, y25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# default kernel (rbf), no weights\n",
        "svc_classifier_grid_25 = GridSearchCV(svm.SVC(), param_grid=param_grid)\n",
        "clf_grid_25 = svc_classifier_grid_25.fit(x25,y25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# default kernel (rbf), weights\n",
        "svc_classifier_grid_25 = GridSearchCV(svm.SVC(class_weight=weight_dict_25), param_grid=param_grid, n_jobs=8)\n",
        "clf_grid_weighted_25 = svc_classifier_grid_25.fit(x25,y25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ]
        }
      ],
      "source": [
        "# linear kernel, no weights\n",
        "svc_classifier_grid_25 = GridSearchCV(svm.LinearSVC(), cv=5, param_grid=param_grid, n_jobs=8)\n",
        "clf_grid_linear_25 = svc_classifier_grid_25.fit(x25,y25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linear kernel, weights\n",
        "svc_classifier_grid_25 = GridSearchCV(svm.LinearSVC(class_weight=weight_dict_25), param_grid=param_grid, cv=5, n_jobs=8)\n",
        "clf_grid_weighted_linear_25 = svc_classifier_grid_25.fit(x25,y25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prediction + Evaluation for Top 25% models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  0.9384684147794994\n",
            "Balanced Accuracy:  0.5492895169344248\n",
            "Precision:  0.0075\n",
            "Recall:  0.15789473684210525\n",
            "F1:  0.01431980906921241\n",
            "[[6296  397]\n",
            " [  16    3]]\n"
          ]
        }
      ],
      "source": [
        "y25_cnn_test = cnn_scaled_test_25['Popular']\n",
        "x25_cnn_test = cnn_scaled_test_25.drop('Popular', axis=1)\n",
        "\n",
        "cnn_default_25 = clf_25.predict(x25_cnn_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y25_cnn_test, cnn_default_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  0.9408522050059595\n",
            "Balanced Accuracy:  0.55048479558376\n",
            "Precision:  0.0078125\n",
            "Recall:  0.15789473684210525\n",
            "F1:  0.01488833746898263\n",
            "[[6312  381]\n",
            " [  16    3]]\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_25 = clf_grid_25.predict(x25_cnn_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y25_cnn_test, cnn_grid_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.9971692491060786\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[6693    0]\n",
            " [  19    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_weighted_25 = clf_grid_weighted_25.predict(x25_cnn_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y25_cnn_test, cnn_grid_weighted_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear\n",
            "Accuracy:  0.9971692491060786\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[6693    0]\n",
            " [  19    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_linear_25 = clf_grid_linear_25.predict(x25_cnn_test)\n",
        "print('grid - linear')\n",
        "print(model_metrics(y25_cnn_test, cnn_grid_linear_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.9971692491060786\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[6693    0]\n",
            " [  19    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "cnn_grid_linear_weighted_25 = clf_grid_weighted_linear_25.predict(x25_cnn_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y25_cnn_test, cnn_grid_linear_weighted_25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for BBC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  1.0\n",
            "Balanced Accuracy:  1.0\n",
            "Precision:  1.0\n",
            "Recall:  1.0\n",
            "F1:  1.0\n",
            "[[1148]]\n"
          ]
        }
      ],
      "source": [
        "y25_bbc_test = bbc_scaled_test_25['Popular']\n",
        "x25_bbc_test = bbc_scaled_test_25.drop('Popular', axis=1)\n",
        "\n",
        "bbc_default_25 = clf_25.predict(x25_bbc_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y25_bbc_test, bbc_default_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  1.0\n",
            "Balanced Accuracy:  1.0\n",
            "Precision:  1.0\n",
            "Recall:  1.0\n",
            "F1:  1.0\n",
            "[[1148]]\n"
          ]
        }
      ],
      "source": [
        "bbc_grid_25 = clf_grid_25.predict(x25_bbc_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y25_bbc_test, bbc_grid_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.7970383275261324\n",
            "Balanced Accuracy:  0.7970383275261324\n",
            "Precision:  1.0\n",
            "Recall:  0.7970383275261324\n",
            "F1:  0.8870576829859428\n",
            "[[  0   0]\n",
            " [233 915]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ]
        }
      ],
      "source": [
        "bbc_grid_weighted_25 = clf_grid_weighted_25.predict(x25_bbc_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y25_bbc_test, bbc_grid_weighted_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.7970383275261324\n",
            "Balanced Accuracy:  0.7970383275261324\n",
            "Precision:  1.0\n",
            "Recall:  0.7970383275261324\n",
            "F1:  0.8870576829859428\n",
            "[[  0   0]\n",
            " [233 915]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ]
        }
      ],
      "source": [
        "bbc_grid_linear_weighted_25 = clf_grid_weighted_linear_25.predict(x25_bbc_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y25_bbc_test, bbc_grid_linear_weighted_25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for Reuters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  0.14085267134376686\n",
            "Balanced Accuracy:  0.5021888680425266\n",
            "Precision:  0.13759479956663057\n",
            "Recall:  1.0\n",
            "F1:  0.2419047619047619\n",
            "[[   7 1592]\n",
            " [   0  254]]\n"
          ]
        }
      ],
      "source": [
        "y25_reuters_test = reuters_scaled_test_25['Popular']\n",
        "x25_reuters_test = reuters_scaled_test_25.drop('Popular', axis=1)\n",
        "\n",
        "reuters_default_25 = clf_25.predict(x25_reuters_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y25_reuters_test, reuters_default_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - default settings\n",
            "Accuracy:  0.14085267134376686\n",
            "Balanced Accuracy:  0.5021888680425266\n",
            "Precision:  0.13759479956663057\n",
            "Recall:  1.0\n",
            "F1:  0.2419047619047619\n",
            "[[   7 1592]\n",
            " [   0  254]]\n"
          ]
        }
      ],
      "source": [
        "reuters_grid_25 = clf_grid_25.predict(x25_reuters_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y25_reuters_test, reuters_grid_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - weighted\n",
            "Accuracy:  0.8629249865083648\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[1599    0]\n",
            " [ 254    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "reuters_grid_weighted_25 = clf_grid_weighted_25.predict(x25_reuters_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y25_reuters_test, reuters_grid_weighted_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.8629249865083648\n",
            "Balanced Accuracy:  0.5\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[1599    0]\n",
            " [ 254    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "reuters_grid_linear_weighted_25 = clf_grid_weighted_linear_25.predict(x25_reuters_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y25_reuters_test, reuters_grid_linear_weighted_25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction for PressTV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clf - default settings\n",
            "Accuracy:  0.14098360655737704\n",
            "Balanced Accuracy:  0.14098360655737704\n",
            "Precision:  1.0\n",
            "Recall:  0.14098360655737704\n",
            "F1:  0.24712643678160917\n",
            "[[   0    0]\n",
            " [1048  172]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ]
        }
      ],
      "source": [
        "y25_press_test = press_scaled_test_25['Popular']\n",
        "x25_press_test = press_scaled_test_25.drop('Popular', axis=1)\n",
        "\n",
        "press_default_25 = clf_25.predict(x25_press_test)\n",
        "print('clf - default settings')\n",
        "print(model_metrics(y25_press_test, press_default_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "press_grid_25 = clf_grid_25.predict(x25_press_test)\n",
        "print('grid - default settings')\n",
        "print(model_metrics(y25_press_test, press_grid_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "press_grid_weighted_25 = clf_grid_weighted_25.predict(x25_press_test)\n",
        "print('grid - weighted')\n",
        "print(model_metrics(y25_press_test, press_grid_weighted_25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grid - linear + weighted\n",
            "Accuracy:  0.0\n",
            "Balanced Accuracy:  0.0\n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "F1:  0.0\n",
            "[[   0    0]\n",
            " [1220    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1854: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n",
            "C:\\Users\\jputz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "press_grid_linear_weighted_25 = clf_grid_weighted_linear_25.predict(x25_press_test)\n",
        "print('grid - linear + weighted')\n",
        "print(model_metrics(y25_press_test, press_grid_linear_weighted_25))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Experiment_Design_SVM_All.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
